# 30-Day Data Science Challenge

Welcome to the 30-Day Data Science Challenge repository!

## Introduction
This repository contains the code and resources for the 30-day data science challenge. Each day, we will tackle a mini data science project to sharpen our skills and explore various aspects of data analysis, machine learning, and more.

## Project Overview
### Day 1: Exploring Seabed Sonar Data
- **Objective:** Differentiate rocks from mines using machine learning on sonar signals.
- **Techniques:** Data preprocessing, machine learning modeling.
- **Tools:** Python, Jupyter Notebooks, scikit-learn.
- **Repository Content:** [Day 01 Folder](Day-01)
  
### Day 2: Fake News Detection Using Python & Machine Learning
- **Objective:** Develop a model to differentiate between real and fake news articles using Python and machine learning.
- **Techniques:** Natural Language Processing (NLP), Feature engineering, Machine learning classification
- **Tools:** Python, Jupyter Notebooks, scikit-learn, NLTK (Natural Language Toolkit)
- **Repository Content:** [Day 02 Folder](Day-02)

### Day 3: House Price Prediction Using XGBoost Regression
- **Objective:** Fine-tune and evaluate the XGBoost regression model to predict house prices accurately.
- **Techniques:** Hyperparameter tuning, Model evaluation, Feature importance analysis.
- **Tools:** Python, Jupyter Notebooks, scikit-learn, XGBoost.
- **Repository Content:** [Day 03 Folder](Day-03)

### Day 4: Credit Card Fraud Detection 
- **Objective:** Implement machine learning algorithms to accurately identify fraudulent credit card transactions.
- **Techniques:** Utilizing data preprocessing for handling imbalanced data and outliers, applying supervised learning algorithms such as Random Forest and Logistic Regression, evaluating models with precision, recall, and F1-score, and incorporating advanced anomaly detection techniques.
- **Tools:** Python, Jupyter Notebooks, scikit-learn, Pandas, NumPy.
- **Repository Content:** [Day 04 Folder](Day-04)
- **Data Source:** [data](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud?resource=download/)

### Day 5: Image Data Processing for Deep Learning
- **Objective:** Harness the power of Python to preprocess image data for deep learning applications.
- **Techniques:** Image preprocessing techniques for scaling, normalization, and augmentation; utilizing deep learning frameworks like TensorFlow and PyTorch for efficient image processing; evaluating model performance with accuracy, precision, recall, and confusion matrices; exploring advanced applications in computer vision and image recognition.
- **Tools:** Python, Jupyter Notebooks, TensorFlow, PyTorch, OpenCV, scikit-image.
- **Repository Content:** [Day 05 Folder](Day-05)

### Day 6: Sentiment Analysis with LSTM Networks on IMDB Reviews
- **Objective:** Unleash the potential of Long Short-Term Memory (LSTM) networks for sentiment analysis on IMDB movie reviews.
- **Techniques:** Data preprocessing: Cleaning, tokenization, and padding sequences.
Model building: Constructing LSTM networks with embedding layers and configuring hyperparameters.
Model training and evaluation: Splitting data, monitoring performance, and assessing accuracy with metrics like loss and accuracy.
- **Tools:** Python, Jupyter Notebooks, TensorFlow/Keras, NLTK.
- **Repository Content:** [Day 06 Folder](Day-06)

### Day 7: Building a Conversational Chatbot using OpenAI's GPT-4 API with Streamlit 
- **Objective:** Create a conversational chatbot using OpenAI's GPT-4 API, seamlessly integrated into a Streamlit web app to showcase the potential of GPT-4 in generating human-like responses and the simplicity of Streamlit for building interactive web applications. 
- **Techniques:** API Integration: Connecting to the OpenAI GPT-4 API.
Web App Development: Using Streamlit to create an interactive user interface.
Conversation Management: Handling user inputs and generating dynamic responses.
Deployment: Running the web app locally or deploying it to a cloud service
- **Tools:** Python, Streamlit, OpenAI GPT-4 API
- **Repository Content:** [Day 07 Folder](Day-07)

### Day 8: Bank Loan Prediction
- **Objective:** Develop a web app to predict bank loan approvals using historical data and machine learning.
- **Techniques:** Data Preprocessing: Handle missing values, encode categorical data, scale features.
Machine Learning: Train and evaluate a Logistic Regression model.
Web Development: Create an interactive user interface with Streamlit.
- **Tools:** Python, Pandas, Scikit-learn, Streamlit.
- **Repository Content:** [Day 08 Folder](Day-08)

### Day 9: Predicting Breast Cancer with Neural Networks in PyTorch 
- **Objective:** Delve into predicting breast cancer using neural networks with PyTorch in our latest project.
- **Techniques:** Data Preprocessing: Handle and prepare the data for training.
Model Architecture: Design and implement an effective neural network.
Training: Train the model for accurate predictions.
Evaluation: Assess the model's performance.
- **Tools:** Python, PyTorch.
- **Repository Content:** [Day 09 Folder](Day-09)

### Day 10: Chatbot with Google's Gemini Pro API using Streamlit 
- **Objective:** This project builds a chatbot web app using Google's Gemini Pro API for conversation and Streamlit for the user interface.
- **Techniques:** API Integration: Connecting to Google's Gemini Pro API for robust conversational capabilities.
Building the Web App: Setting up Streamlit for a responsive and interactive user interface.
User Experience Design: Ensuring smooth and intuitive interactions within the chatbot interface.
- **Tools:** Python, Streamlit, Google's Gemini Pro API, Requests Library.
- **Repository Content:** [Day 10 Folder](Day-10)

### Day 11: Dog vs Cat Classification System using Transfer Learning 
- **Objective:** This project aims to classify dogs and cats in images using transfer learning. A pre-trained MobileNet V2 model will be used for fast and accurate image classification.
- **Techniques:** This project builds a dog vs cat classifier using a pre-trained MobileNet V2 for speed and efficiency. It involves data prep (resizing, normalization, augmentation), fine-tuning the model, and evaluating its performance with various metrics.
- **Tools:** Python, TensorFlow/Keras, MobileNet V2, NumPy and Pandas, Matplotlib for Visualization.
- **Repository Content:** [Day 11 Folder](Day-11)

### Day 12: Titanic Survival Prediction
- **Objective:** This project is to build and evaluate a Logistic Regression model to predict Titanic passenger survival, focusing on data preprocessing, feature engineering, and model performance assessment.
- **Techniques:** Logistic Regression: Building an effective binary classifier to predict survival.
Data Preprocessing: Handling missing values, feature engineering, and normalization to ensure data quality.
Feature Engineering: Creating meaningful features from raw data to improve model performance.
Model Evaluation: Using accuracy, precision, recall, and ROC-AUC to assess model performance.
- **Tools:** Python, Pandas, NumPy, Scikit-learn, Matplotlib, Seaborn.
- **Repository Content:** [Day 12 Folder](Day-12)
- **Data Source:** [data](https://www.kaggle.com/c/titanic/data)

### Day 13: Spam Mail Prediction System
- **Objective:** Develop a robust Spam Mail prediction system using machine learning and natural language processing techniques to effectively identify and filter out spam emails.
- **Techniques:** Natural Language Processing (NLP): Utilizing text processing techniques to handle email content.
Feature Engineering: Extracting meaningful features from email text to enhance model performance.
Model Selection: Implementing various machine learning algorithms to find the most effective model.
Evaluation and Metrics: Assessing model accuracy with precision, recall, and F1 score, and refining it for optimal results.
- **Tools:** Python, Scikit-learn, NLTK and SpaCy, Pandas, NumPy , Matplotlib, Seaborn 
- **Repository Content:** [Day 13 Folder](Day-13)

### Day 14: Wine Quality Prediction
- **Objective:** Create a Wine Quality prediction system using machine learning to accurately assess and classify wine based on various chemical properties.
- **Techniques:** Data Preprocessing: Cleaning and preparing the wine dataset for analysis.
Feature Engineering: Extracting key features that influence wine quality.
Model Selection: Applying different machine learning models to find the best fit for our data.
Evaluation and Metrics: Using RMSE, MAE, and RÂ² to evaluate and refine model performance.
- **Tools:** Python, Scikit-learn, Pandas, NumPy, Matplotlib and Seaborn.
- **Repository Content:** [Day 14 Folder](Day-14)
- **Data Source:** [data](https://www.kaggle.com/datasets/uciml/red-wine-quality-cortez-et-al-2009)

### Day 15: Heart Disease Prediction
- **Objective:** Develop a reliable Heart Disease prediction system using machine learning to assist in early diagnosis and treatment planning based on patient data.
- **Techniques:** Data Preprocessing: Clean and prepare patient data.
Feature Engineering: Identify key features influencing heart disease.
Model Selection: Apply and evaluate various machine learning models.
Evaluation and Metrics: Use accuracy, precision, recall, and ROC-AUC scores to assess performance.
- **Tools:** Python, Scikit-learn, Pandas and NumPy, Matplotlib and Seaborn for Visualization.
- **Repository Content:** [Day 15 Folder](Day-15)

### Day 16: Customer Segmentation System using K-Means Clustering
- **Objective:** To develop a Customer Segmentation system using K-Means clustering to categorize customers based on purchasing behavior, enabling targeted marketing strategies.
- **Techniques:** Data Preprocessing: Cleaning and preparing customer data for analysis.
Feature Engineering: Extracting and selecting relevant features that influence customer segmentation.
Clustering with K-Means: Implementing the K-Means algorithm to identify customer segments.
Evaluation and Metrics: Using silhouette scores and elbow method to validate and refine clusters.
- **Tools:** Python, Scikit-learn, Pandas, NumPy, Matplotlib, Seaborn.
- **Repository Content:** [Day 16 Folder](Day-16)
- **Data Source:** [data](https://www.kaggle.com/datasets/vjchoudhary7/customer-segmentation-tutorial-in-python)

### Day 17: Sales Dashboard (PowerBI)
- **Objective:** Conduct a comprehensive E-Commerce Sales Analysis using Power BI to gain insights into sales performance and customer behavior for informed business decisions.
- **Techniques:** Data Collection: Gathering sales data from various e-commerce platforms.
Data Cleaning: Preparing and refining the dataset for analysis.
Data Modeling: Structuring data for effective visualization and analysis.
Interactive Dashboards: Creating dynamic and interactive dashboards to explore sales metrics.
Insights and Reporting: Identifying key insights and generating comprehensive reports.
- **Tools:** Power BI
- **Repository Content:** [Day 17 Folder](Day-17)

### Day 18: Data Analytics Project using Python and SQL
- **Objective:** Conduct a comprehensive data analytics project using Python and SQL, to acquire, process, and analyze datasets from Kaggle.
- **Techniques:** Data Acquisition: Kaggle API for dataset download.
Data Processing: Pandas for cleaning and preparation.
Data Loading: SQL Server for database storage and analysis.
- **Tools:** Python, Kaggle API, Pandas, SQL Server.
- **Repository Content:** [Day 18 Folder](Day-18)

### Day 19: Sales Analysis
- **Objective:** Perform a comprehensive sales analysis using Python and Tableau to uncover insights and trends that inform business decisions.
- **Techniques:** Data Collection, Data Cleaning, Data Modeling, Insights and Reporting. 
- **Tools:** Python, Pandas, NumPy, Matplotlib, Seaborn.
- **Repository Content:** [Day 19 Folder](Day-19)

### Day 20: Text Extraction Project
- **Objective:** Extract and preprocess text from images and scanned documents using Pytesseract to automate and streamline data entry tasks.
- **Techniques:** Data Collection, Data Cleaning, Automation. 
- **Tools:** Python, Pytesseract.
- **Repository Content:** [Day 20 Folder](Day-20)

### Day 21: Fashion MNIST Image Classification
- **Objective:** Develop a CNN-based model to classify fashion items from the Fashion MNIST dataset with high accuracy.
- **Techniques:** Data Preprocessing, Model Building, Model Evaluation.
- **Tools:** Python, TensorFlow, Streamlit, Pandas, NumPy, Matplotlib.
- **Repository Content:** [Day 21 Folder](Day-21)

### Day 22: Loan Prediction System
- **Objective:** Build a Python system that analyzes borrower data to predict loan eligibility using machine learning.
- **Techniques:** Data Preprocessing, Feature Engineering, Model Building & Training, Model Evaluation. 
- **Tools:** Python, Pandas, NumPy, Matplotlib, Sklearn and Seaborn.
- **Repository Content:** [Day 22 Folder](Day-22)
- **Data Source:** [data](https://www.kaggle.com/datasets/ninzaami/loan-predication)

### Day 23: Car Price Prediction
- **Objective:** Build a machine learning model to predict car prices accurately based on various features and specifications.
- **Techniques:** Data Preprocessing: Cleaning and preparing the car dataset for analysis.
Feature Engineering: Selecting and transforming key features that influence car prices.
Model Building: Implementing and comparing different machine learning models to find the best predictor.
Model Evaluation: Using metrics such as RMSE, MAE, and RÂ² to assess and refine model performance.
- **Tools:** Python, Scikit-learn, Pandas and NumPy, Matplotlib and Seaborn.
- **Repository Content:** [Day 23 Folder](Day-23)
- **Data Source:** [data](https://www.kaggle.com/datasets/nehalbirla/vehicle-dataset-from-cardekho)

### Day 24: Medical Insurance Cost Prediction
- **Objective:** To build a machine learning model to predict medical insurance costs accurately based on various health and demographic factors.
- **Techniques:** Data Preprocessing, Feature Engineering, Model Building, Model Evaluation.
- **Tools:** Python, Scikit-learn, Pandas and NumPy, Matplotlib and Seaborn.
- **Repository Content:** [Day 24 Folder](Day-24)
- **Data Source:** [data](https://www.kaggle.com/datasets/mirichoi0218/insurance)

### Day 25: CIFAR-10 Object Recognition System
- **Objective:** Develop a CIFAR-10 Object Recognition system using ResNet50 with Transfer Learning to achieve high accuracy in identifying various objects.
- **Techniques:** Data Preprocessing, Transfer Learning, Model Fine-Tuning, Evaluation.
- **Tools:** Python, TensorFlow/Keras, NumPy, Pandas, Matplotlib, Seaborn.
- **Repository Content:** [Day 25 Folder](Day-25)

### Day 26: Music Genre Classification
- **Objective:** Build a machine learning model to classify music tracks into genres based on extracted audio features.
- **Techniques:** Data Preprocessing, Feature Extraction, Model Building, Model Evaluation.
- **Tools:** Python, LibROSA, Scikit-learn, Pandas, NumPy, Matplotlib, Seaborn.
- **Repository Content:** [Day 26 Folder](Day-26)

## Getting Started
To get started with the challenge:
1. Clone this repository to your local machine.
2. Navigate to the folder of the current day's project.
3. Follow the instructions provided in the project's README to set up your environment and run the code.

## Contributions
Contributions are welcome! If you have suggestions for improvements, new project ideas, or would like to contribute code, feel free to submit a pull request.

## Acknowledgments
A big thank you to everyone participating in this challenge! Let's learn, grow, and conquer the world of data science together!

## Connect with Us
- LinkedIn: [Anchal Singh Tanwar ](https://www.linkedin.com/in/anchal-singh-tanwar-858b21228/)

